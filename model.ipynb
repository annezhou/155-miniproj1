{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS155: Miniproject 1\n",
    "Kavya Sreedhar, Audrey Wang, Anne Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seed the random number generator.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Define function for loading files\n",
    "def load_data(filename, skiprows=1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data.\n",
    "train = load_data('training_data.txt')\n",
    "X_test = load_data('test_data.txt')\n",
    "\n",
    "X_train = train[:, 1:]\n",
    "y_train = train[:, 0]\n",
    "N_train = len(X_train)\n",
    "N_test = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data.\n",
    "max_vals = X_train.max(axis=0)\n",
    "X_train = X_train / max_vals\n",
    "X_test = X_test / max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: 0.530500\n",
      "[ 0.53073463  0.5303826   0.5303826 ]\n",
      "\n",
      "logistic regression: 0.829997\n",
      "[ 0.84332834  0.8372093   0.80945236]\n",
      "\n",
      "random forest: 0.753246\n",
      "[ 0.76911544  0.76294074  0.72768192]\n",
      "\n",
      "gradient boost: 0.786494\n",
      "[ 0.81034483  0.79969992  0.74943736]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find cross-validation score of different models to determine best one.\n",
    "X_val = X_train[:4000]\n",
    "y_val = y_train[:4000]\n",
    "types = ['svm', 'logistic regression', 'random forest', 'gradient boost']\n",
    "scores = []\n",
    "\n",
    "sv = svm.SVC()\n",
    "log = LogisticRegression()\n",
    "random_forest = RandomForestClassifier()\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "scores.append(cross_val_score(sv, X_val, y_val))\n",
    "scores.append(cross_val_score(log, X_val, y_val))\n",
    "scores.append(cross_val_score(random_forest, X_val, y_val))\n",
    "scores.append(cross_val_score(gradient_boost, X_val, y_val))\n",
    "\n",
    "for i in range(len(types)):\n",
    "    print('%s: %f' % (types[i], np.mean(scores[i])))\n",
    "    print(scores[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweak parameters for best classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions to output file.\n",
    "predictions = model.predict(x=X_test).flatten()\n",
    "f = open('predictions.txt', 'w')\n",
    "f.write('Id,Prediction')\n",
    "for i in range(len(predictions)):\n",
    "    f.write('%d,%d\\n' % ((i + 1), predictions[i]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "# from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 13s 632us/step - loss: 0.2573 - acc: 0.7679\n",
      "20000/20000 [==============================] - 2s 120us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.074854408216476445, 0.92405000000000004]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 1000 # Number of parameters\n",
    "\n",
    "# # Define the model.\n",
    "# model = Sequential()\n",
    "# model.add(Dense(1000, input_shape=(N,)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(900))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(800))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Print number of params\n",
    "# model.count_params()\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='mse',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # Train the model for 1 epoch\n",
    "# history = model.fit(X_train, y_train, epochs=1, batch_size=32)\n",
    "\n",
    "# # Evaluate the model\n",
    "# model.evaluate(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
