{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS155: Miniproject 1\n",
    "Kavya Sreedhar, Audrey Wang, Anne Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random number generator.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Define function for loading files\n",
    "def load_data(filename, skiprows=1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "train = load_data('training_data.txt')\n",
    "X_test = load_data('test_data.txt')\n",
    "\n",
    "X_train = train[:, 1:]\n",
    "y_train = train[:, 0]\n",
    "N_train = len(X_train)\n",
    "N_test = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data.\n",
    "max_vals = X_train.max(axis=0)\n",
    "X_train = X_train / max_vals\n",
    "X_test = X_test / max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.2101 - acc: 0.7785\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.0881 - acc: 0.8931\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.0596 - acc: 0.9369\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.0443 - acc: 0.9579\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.0338 - acc: 0.9713\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.0274 - acc: 0.9769\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.0225 - acc: 0.9815\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.0218 - acc: 0.9812\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.0210 - acc: 0.9816\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.0169 - acc: 0.9863\n",
      "20000/20000 [==============================] - 6s 316us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009327512240409851, 0.99475]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000 # Number of parameters\n",
    "\n",
    "# Define the model.\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(N,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(900))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(800))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Print number of params\n",
    "model.count_params()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 1 epoch\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions to output file.\n",
    "predictions = model.predict(x=X_test).flatten()\n",
    "f = open('predictions.txt', 'w')\n",
    "f.write('Id,Prediction\\n')\n",
    "for i in range(len(predictions)):\n",
    "    f.write('%d,%d\\n' % ((i + 1), predictions[i]))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
